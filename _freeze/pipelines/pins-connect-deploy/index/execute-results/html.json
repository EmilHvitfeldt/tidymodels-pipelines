{
  "hash": "ad1ad34fcbb9de7cf676b5ff633e7e62",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Vetiver and Posit Connect\ndescription: \"Using vetiver to version a model on Posit Connect as an endpoint, and predict from it\"\nimage: ../../images/pins-connect-deploy.jpg\ncategories:\n  - pins\n  - vetiver\n  - Posit Connect\n---\n\n\n::: {.callout-note}\nThis page was last generated on 2024-03-08. If you find the code out of date please [file an issue](https://github.com/EmilHvitfeldt/tidymodels-pipelines/issues/new).\n:::\n\n::: new\n::: {.callout-note}\n## Changes from standard\n\nAll changes from the [standard pipeline](../standard/index.qmd) is highlighted with a cranberry line to the right.\n:::\n:::\n\n::: new\n\n## Loading packages\n\nWe are using the tidymodels package to do the modeling, [embed](https://embed.tidymodels.org/) for target encoding, [pins](https://pins.rstudio.com/) for versioning,  [vetiver](https://vetiver.rstudio.com/) for version and deployment, and [rsconnect](https://rstudio.github.io/rsconnect/) for connecting with [Posit Connect](https://posit.co/products/enterprise/connect/).\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# install.packages(\"pak\")\n# pak::pak(\"tidymodels\", \"embed\", \"vetiver\", \"pins\", \"rsconnect\")\nlibrary(tidymodels)\nlibrary(embed)\nlibrary(vetiver)\nlibrary(pins)\nlibrary(rsconnect)\n```\n:::\n\n\n:::\n\n::: new\n\n## Loading data from Posit Connect with pins\n\nWe will fetch data from and version the final model on [Posit Connect](https://posit.co/products/enterprise/connect/) using the [pins](https://pins.rstudio.com/) package.\n\nFor the smoothest experience, we recommend that you authenticate using environment variables. The two variables you will need are `CONNECT_SERVER` and `CONNECT_API_KEY`.\n\n::: {.callout-tip}\nThe function [usethis::edit_r_environ()](https://usethis.r-lib.org/reference/edit.html) can be very handy to open `.Renviron` file to specify your environment variables.\n:::\n\n`CONNECT_SERVER` is the URL of the posit connect page. So if your connect server is accessed through `https://example.com/connect/#/content/` then you can find `CONNECT_SERVER` by removing `connect/` and everything that follows it, leaving you with `https://example.com/`.\n\n`CONNECT_API_KEY` is created through your Connect server. \n1. Click on your name in the upper right upper right.\n1. Click `API keys`.\n1. Click `New API Key`.\n1. Give your API a key, click ``Create Key`.\n\nOnce you have those two, you can add them to your `.Renviron` file in the following format:\n\n```markdown\nCONNECT_API_KEY=xxxxxxxxxxxxxxxxxxxxxxxxxxxx\nCONNECT_SERVER=https://example.com/\n```\n\nNote that you don't want to put quotes around the values. \n\n## Loading Data\n\nWe are using the smaller `laxflights2022` data set described on the [data preparation](../../data-prep.qmd) page. The data set has been uploaded to pins, as described on the [data pins](../../data-pins.qmd#posit-connect) page. This is meant to simulate this workflow where we stay inside Connect as much as possible.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboard <- board_connect()\n\nflights <- board |> \n  pin_read(\"emil.hvitfeldt/laxflights2022_lite\")\n\nglimpse(flights)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nRows: 3,757\nColumns: 8\n$ arr_delay <dbl> 4, -15, -12, 38, -9, -17, 5, 12, -40, 6, -7, 28, 25, -9, 180…\n$ dep_delay <dbl> 9, -8, 0, -7, 3, 6, 29, -1, 2, 7, 6, 13, 34, -2, 191, 52, 9,…\n$ carrier   <chr> \"UA\", \"OO\", \"AA\", \"UA\", \"OO\", \"OO\", \"UA\", \"AA\", \"DL\", \"DL\", …\n$ tailnum   <chr> \"N37502\", \"N198SY\", \"N410AN\", \"N77261\", \"N402SY\", \"N509SY\", …\n$ origin    <chr> \"LAX\", \"LAX\", \"LAX\", \"LAX\", \"LAX\", \"LAX\", \"LAX\", \"LAX\", \"LAX…\n$ dest      <chr> \"KOA\", \"EUG\", \"HNL\", \"DEN\", \"FAT\", \"SFO\", \"MCO\", \"MIA\", \"OGG…\n$ distance  <dbl> 2504, 748, 2556, 862, 209, 337, 2218, 2342, 2486, 862, 156, …\n$ time      <dttm> 2022-01-01 13:15:00, 2022-01-01 14:00:00, 2022-01-01 14:45:…\n```\n\n\n:::\n:::\n\n\n:::\n\n## Modeling\n\nAs a reminder, the modeling task we are trying to accomplish is the following:\n\n> Given all the information we have, from the moment the plane leaves for departure. Can we predict the arrival delay `arr_delay`.\n\nOur outcome is `arr_delay` and the remaining variables are predictors. We will be fitting a xgboost model as a regression model.\n\n### Splitting Data\n\nSince the data set is already in chronological order, we can create a time split of the data using `initial_time_split()`, this will put the first 75% of the data into the training data set, and the remaining 25% into the testing data set. \n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(1234)\n\nflights_split <- initial_time_split(flights, prop = 3/4)\nflights_training <- training(flights_split)\n```\n:::\n\n\nSince we are doing hyperparameter tuning, we will also be creating a cross-validation split\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_folds <- vfold_cv(flights_training)\n```\n:::\n\n\n### Feature Engineering\n\nWe need to do a couple of things to make this data set work for our model. The datetime variable `time` needs to be transformed, as does the categorical variables `carrier`, `tailnum`, `origin` and `dest`.\n\nFrom the `time` variable, the month and day of the week are extracted as categorical variables, then the day of year and time of day are extracted as numerics. The `origin` and `dest` variables will be turned into dummy variables, and `carrier`, `tailnum`, `time_month`, and `time_dow` will be converted to numerics with likelihood encoding.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nflights_rec <- recipe(arr_delay ~ ., data = flights_training) %>%\n  step_novel(all_nominal_predictors()) %>%\n  step_other(origin, dest, threshold = 0.025) %>%\n  step_dummy(origin, dest) %>%\n  step_date(time, \n            features = c(\"month\", \"dow\", \"doy\"), \n            label = TRUE, \n            keep_original_cols = TRUE) %>%\n  step_time(time, features = \"decimal_day\", keep_original_cols = FALSE) %>%\n  step_lencode_mixed(all_nominal_predictors(), outcome = vars(arr_delay)) %>%\n  step_zv(all_predictors())\n```\n:::\n\n\n### Specifying Models\n\nWe will be fitting a boosted tree model in the form of a [xgboost model](https://parsnip.tidymodels.org/reference/details_boost_tree_xgboost.html).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_spec <-\n  boost_tree(\n    trees = tune(),\n    min_n = tune(),\n    mtry = tune(),\n    learn_rate = 0.01\n  ) %>%\n  set_engine(\"xgboost\") %>%\n  set_mode(\"regression\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_wf <- workflow(flights_rec, xgb_spec)\n```\n:::\n\n\n\n### Hyperparameter Tuning\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndoParallel::registerDoParallel()\n\nxgb_rs <- tune_grid(\n  xgb_wf,\n  resamples = flights_folds,\n  grid = 10\n)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\ni Creating pre-processing data to finalize unknown parameter: mtry\n```\n\n\n:::\n:::\n\n\nWe can visualize the performance of the different hyperparameter selections\n\n\n::: {.cell}\n\n```{.r .cell-code}\nautoplot(xgb_rs)\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\nand look at the top result\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshow_best(xgb_rs, metric = \"rmse\")\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 5 × 9\n   mtry trees min_n .metric .estimator  mean     n std_err .config              \n  <int> <int> <int> <chr>   <chr>      <dbl> <int>   <dbl> <chr>                \n1     3  1988     4 rmse    standard    28.1    10    5.88 Preprocessor1_Model01\n2     8   849    13 rmse    standard    29.6    10    6.44 Preprocessor1_Model04\n3     3  1543     9 rmse    standard    29.6    10    6.11 Preprocessor1_Model02\n4    10  1139    14 rmse    standard    30.0    10    6.44 Preprocessor1_Model05\n5    12   554    18 rmse    standard    30.6    10    6.77 Preprocessor1_Model06\n```\n\n\n:::\n:::\n\n\n### Fitting Final Model\n\nOnce we are satisfied with the modeling that has been done, we can fit our final model. We use `finalize_workflow()` to use the best hyperparameters, and `last_fit()` to fit the model to the training data set and evaluate it on the testing data set.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nxgb_last <- xgb_wf %>%\n  finalize_workflow(select_best(xgb_rs, \"rmse\")) %>%\n  last_fit(flights_split)\n```\n:::\n\n\n::: new\n\n## Creating vetiver model\n\n\n::: {.cell}\n\n```{.r .cell-code}\nv <- xgb_last %>%\n  extract_workflow() %>%\n  vetiver_model(\"flights_xgb\")\nv\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n── flights_xgb ─ <bundled_workflow> model for deployment \nA xgboost regression modeling workflow using 7 features\n```\n\n\n:::\n:::\n\n\n## Version model with pins on Posit Connect\n\nOnce that is all done, we can create a board that connects to Connect, and write our vetiver model to the board.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nboard <- board_connect()\nvetiver_pin_write(board, v)\n```\n:::\n\n\nSince we are using `vetiver_deploy_rsconnect()` which uses the {rsconnect} package, we need to make sure that we have the right authetication and settings. We can do this using `rsconnect::connectApiUser()`.\n\n```markdown\nrsconnect::connectApiUser(\n  account = \"account.name\",\n  server = \"https://example.com/\", \n  apiKey = \"....\"\n)\n```\n\nYou will notice that we already have these values, as we got them earlier when we set up the environment variables.\n\n\nOnce we are properly set up, we can use `vetiver_deploy_rsconnect()`, it takes a `board` and the name of endpoint. Depending on your model, it will take a little while to run as it installs what it needs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nendpoint <- vetiver_deploy_rsconnect(\n  board = board, \n  name = \"emil.hvitfeldt/flights_xgb\"\n)\n```\n:::\n\n\nOnce this finishes running, you might get a pop-up website with your endpoint information. It should also print to the console. You can also find it in Connect itself. What we need is the \"CONTENT URL\".\n\n## Make predictions from Connect endpoint\n\nNow that we have the content url we can create an endpoint with `vetiver_endpoint()`, and that endpoint can be used as a way to make predictions. The content url we got earlier should replace `$APP_ID` below. Note that it is very important that we end the endpoint with `/predict`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nendpoint <- vetiver_endpoint(\"https://colorado.posit.co/rsc/content/$APP_ID/predict\")\n```\n:::\n\n\nAnd now we are ready to predict! With the endpoint we can pass in some data set to predict with. Authorization is done in a header that uses the `CONNECT_API_KEY` environment variable we created earlier.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict(\n  endpoint,\n  flights_training,\n  httr::add_headers(Authorization = paste(\"Key\", Sys.getenv(\"CONNECT_API_KEY\")))\n)\n```\n:::\n\n::: {.cell}\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2,817 × 1\n    .pred\n    <dbl>\n 1  -1.79\n 2 -13.3 \n 3 -17.3 \n 4  -3.67\n 5  82.8 \n 6  52.2 \n 7  10.7 \n 8   8.04\n 9  58.1 \n10   5.39\n# ℹ 2,807 more rows\n```\n\n\n:::\n:::\n\n\n:::\n",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}