---
title: AWS, CSV Input, SageMaker Endpoint
description: "Using vetiver to version a model on Amazon SageMaker as an endpoint, and predict from it"
image: ../../images/csv-sagemaker-deploy.jpg
categories:
  - csv
  - vetiver
  - Amazon SageMaker
  - AWS
---

::: {.callout-note}
This page was last generated on 2024-02-29. If you find the code out of date please [file an issue](https://github.com/EmilHvitfeldt/tidymodels-pipelines/issues/new).
:::

{{< include ../../_include-changes-from-standard.qmd >}}

::: new

## Loading packages

We are using the tidymodels package to do the modeling, [embed](https://embed.tidymodels.org/) for target encoding, [pins](https://pins.rstudio.com/) for versioning,  [vetiver](https://vetiver.rstudio.com/) for version and deployment, and [smdocker](https://dyfanjones.r-universe.dev/smdocker) for deploying to SageMaker.

```{r}
#| label: setup
#| message: false
# install.packages("pak")
# pak::pak("tidymodels", "embed", "vetiver", "pins", "smdocker")
library(tidymodels)
library(embed)
library(vetiver)
library(pins)
library(smdocker)
```

:::

## Loading Data

We are using the smaller `laxflights2022` data set described on the [data preparation](../../data-prep.qmd) page.

```{r}
#| label: loading-data
#| message: false
flights <- readr::read_csv(here::here("data/laxflights2022_lite.csv"))

glimpse(flights)
```

{{< include ../../_include-modeling.qmd >}}

## Creating vetiver model

```{r}
v <- xgb_last %>%
  extract_workflow() %>%
  vetiver_model("flights_xgb")
v
```

## Version model with pins on Amazon SageMaker

We will version this model on [Amazon S3](https://aws.amazon.com/s3/) using the [pins](https://pins.rstudio.com/) package.

{{< include ../../_include-envvar-s3.qmd >}}

Once that is all done, we can create a board that connects to Amazon S3, and write our vetiver model to the board. Now that you have set up the environment variables, we can create a pins board. When using S3 you need to specify a bucket and its region. This cannot be done with Pins and has to be done beforehand.

```{r}
#| message: false
board <- board_s3(
  "tidymodels-pipeline-example",
  region = "us-west-1"
)
vetiver_pin_write(board, v)
```

Since we are using `vetiver_deploy_sagemaker()` which uses the {smdocker} package, we need to make sure that we have the right authetication and settings.

If you are working locally, you will likely need to explicitly set up your execution role to work correctly. Check out [Execution role requirements](https://dyfanjones.r-universe.dev/smdocker) in the smdocker documentation, and especially note that the bucket containing your vetiver model needs to be added as a resource in your IAM role policy.

Once we are properly set up, we can use `vetiver_deploy_sagemaker()`, it takes a `board`, the name of endpoint and the `instance_type` Look at the [Amazon SageMaker pricing](https://aws.amazon.com/sagemaker/pricing/) to help you decide what you need. Depending on your model, it will take a little while to run as it installs what it needs.

```{r}
#| eval: false
new_endpoint <- vetiver_deploy_sagemaker(
  board = board,
  name = "flights_xgb",
  instance_type = "ml.t2.medium"
)
```

## Make predictions from Connect endpoint

With the endpoint we can pass in some data set to predict with.

```{r}
#| eval: false
predict(
  new_endpoint,
  flights_training
)
```

```{r}
#| echo: false
tibble::tibble(
  .pred = c(-1.7894, -13.3206, -17.2753, -3.6661, 82.8237, 52.177, 10.7185, 8.0357, 58.146, 5.3933, rep(0, 2807)),
)
```

:::
